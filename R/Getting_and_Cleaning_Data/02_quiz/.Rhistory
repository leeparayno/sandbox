x <- c(4, "a", TRUE)
class(x)
x <- c(1,3, 5)
y <- c(3, 2, 10)
rbind(x, y)
x <- 1:4
y <- 2
x + y
x <- c(3, 5, 1, 10, 12, 6)
x[x < 6] <- 0
x
swirl
swirl()
library(swirl)
swirl()
1:20
pi:10
15:1
?`:`
seq(1, 20)
seq(0, 10, by=0.5)
seq(5, 10, length=30)
my_seq <- seq(5, 10, length=30)
length(my_seq)
1:length(my_seq)
seq(along.with = my_seq)
seq_along(my_seq)
rep(0, times = 40)
rep(c(0, 1, 2), time = 10)
rep(c(0, 1, 2), times = 10)
rep(c(0, 1, 2), each = 10)
1
swirl()
num_vec <- (0.5, 55, -10, 6)
num_vec <- c(0.5, 55, -10, 6)
num_vect <- c(0.5, 55, -10, 6)
tf <- num_vect < 1
tf
num_vect >= 6
my_char <- c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
c(my_char, "Lee Parayno")
my_name <- c(my_char, "Lee Parayno")
my_name
paste(my_name, collapse = " ")
paste("Hello", "world!", sep = " ")
paste(c(1:3),c("X","Y","Z"),sep = "")
paste(LETTERS, 1:4, sep = "-")
x <- c(44, NA, 5, NA)
x * 3
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y, z), 100)
my_na <- is.na(my_data)
my_na
my_data == NA
sum(my_na,TRUE)
sum(my_na)
my_data
0 / 0
Inf - Inf
x
x[1:10]
x[is.na(x)]
y <- x[!is.na(x)]
y
y[y > 0]
x[x > 0]
x[!is.na(x) & x > 0]
c(x[1,5,7])
c(x[1],x[5],x[7])
x[c(3,5,7)]
x[0]
x[300]
x[3000]
x[c(-2, -10)]
x[-c(2, 10)]
vect <- c(foo = 11, bar = 2, norf = NA)
vect
names(vect)
vect2 <- c(11, 2, NA)
names(vect2) <- c("foo", "bar", "norf")
identical(vect, vect2)
vect["bar"]
vect[c("foo", "bar")]
c(1:20)
my_vector <- c(1:20)
my_vector <- 1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector) <- c(4, 5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix <- my_vector
?matrix
matrix(data = 1:20, nrow = 4, n_col = 5)
matrix(data = 1:20, nrow = 4, ncol = 5)
my_matrix2 = matrix(data = 1:20, nrow = 4, ncol = 5)
identical(my_matrix, my_matrix2)
patients <- c("Bill", "Gina", "Kelly", "Sean")
cbind(patients, my_matrix)
my_data <- data.frame(patients, my_matrix)
my_data
class(my_data)
cnames <- c("patient", "age", "weight", "bp", "rating", "test")
colnames(my_data) <- cnames
my_data
above <- function(x, n) {
use <- x > n
x[use]
}
x <- 1:20
above(x, 10)
cube <- function(x, n) {
x^3
}
cube(3)
x <- 1:10
if(x > 5) {
x <- 0
}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
pwd
pwd()
cwd()
cwd
pwd
getwd()
setwd("/Users/lparayno/Documents/Classes/Data Science/courses/03_GettingData/01_quiz")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", destfile = "./datafss.csv", method = "curl")
list.files(".")
dateDownloaded <- date()
cat("datafss.csv")
idaho <- read.csv("datafss.csv")
idaho
idaho[idaho$VAL == 24]
idaho[,idaho$VAL == 24]
idaho[idaho$VAL == 24,]
idaho[,idaho$VAL == 24]
idaho[idaho$VAL == 24]
idaho[idaho$VAL == "24",]
mil <- idaho[idaho$VAL == "24",]
complete.cases(mil)
good <- complete.cases(mil)
mil[good,]
mil <- idaho[,idaho$VAL]
mil <- idaho[,"VAL"]
mil <- idaho[,idaho$VAL]
mil <- idaho[idaho$VAL == "22",]
mil
comp <- complete.cases(idaho)
comp
idaho[comp]
idaho[comp,]
View(mil)
idaho[complete.cases(idaho),]
idaho <- read.csv("datafss.csv")
idaho[complete.cases(idaho),]
idaho <- read.csv("datafss.csv")
idaho
idaho[idaho$VAL == 24,]
mil <- idaho[idaho$VAL == 24,]
mil
mil[is.na(mil$VAL)]
mil[is.na(mil$VAL),]
mil[,is.na(mil$VAL)]
names(mil)
View(mil)
View(mil)
mil[complete.cases(mil),]
mil[complete.cases(mil$VAL),]
count <- mil[complete.cases(mil$VAL),]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx", destfile = "./NGAP.xlsx", method = "curl")
library(xslx)
install(xslx)
install.packages("xslx")
install.packages("xlsx")
install.packages("xlconnect")
install.packages("XLConnect")
library("xlsx")
rows <- 18:23
cols <- 7:15
ngap <- read.xlsx("./NGAP.xlsx",sheetIndex = 1,rowIndex = rows, colIndex = cols)
ngap
dat <- read.xlsx("./NGAP.xlsx",sheetIndex = 1,rowIndex = rows, colIndex = cols)
sum(dat$Zip*dat$Ext,na.rm=T)
80120*456
library(XML)
install.packages("XML")
library(XML)
doc <- xmlTreeParse("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", useInternal = TRUE)
doc <- xmlTreeParse("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", useInternal = TRUE, method = "curl")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", destfile = "./restaurants.xml", method = "curl")
doc <- xmlTreeParse("./restaurants.xml", useInternal = TRUE)
doc
rootNode <- xmlRoot(doc)
xmlName(rootNode)
xmlSApply(rootNode,xmlValue)
xpathSApply(rootNode, "//name")
xpathSApply(rootNode, "//zip")
rootNode
xpathSApply(rootNode, "//zipcode", xmlValue == 21231)
xpathSApply(rootNode, "//zipcode" == 21231, xmlValue)
xpathSApply(rootNode, "//zipcode", xmlValue)
zip <- xpathSApply(rootNode, "//zipcode", xmlValue)
zip[21231]
zip[ = 21231]
zip = 21231
onezip <- zip = 21231
onezip <- zip == 21231
onezip
onezip <- zip["21231"]
zip
zip <- xpathSApply(rootNode, "//zipcode", xmlValue)
zip
zip["21231"]
count <- table(zip)
count
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destfile = "./housing.csv", method = "curl")
housing <- read.csv("./housing.csv")
?fread
??fread
house <- fread("./housing.csv")
library(data.table)
install.packages("data.table")
library(data.table)
house <- fread("./housing.csv")
house
DT <- fread("./housing.csv")
DT[DT$pwgtp15,]
DT[,DT$pwgtp15]
avg(DT[,DT$pwgtp15])
average(DT[,DT$pwgtp15])
mean(DT[,DT$pwgtp15])
DT[,mean(pwgtp15),by=SEX]
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
mean(DT$pwgtp15,by=DT$SEX)
tapply(DT$pwgtp15,DT$SEX,mean)
DT[,mean(pwgtp15),by=SEX]
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
sapply(split(DT$pwgtp15,DT$SEX),mean)
time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(DT[,mean(pwgtp15),by=SEX])
getwd()
setwd("/Users/lparayno/Documents/Classes/Data Science/courses/03_GettingData/02_quiz")
getwd()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destfile = "./americancommunitysurvey.csv", method= "curl")
library(httr)
source(github)
source("github.R")
source('~/Documents/Classes/Data Science/courses/03_GettingData/02_quiz/github.R')
parseRepos("https://api.github.com/users/jtleek/repos")
source('~/Documents/Classes/Data Science/courses/03_GettingData/02_quiz/github.R')
parseRepos("https://api.github.com/users/jtleek/repos")
git <- parseRepos("https://api.github.com/users/jtleek/repos")
git[[$name]]
source('~/Documents/Classes/Data Science/courses/03_GettingData/02_quiz/github.R')
git <- parseRepos("https://api.github.com/users/jtleek/repos")
install.packages("jsonlite")
install.packages("jsonlite")
git <- parseRepos("https://api.github.com/users/jtleek/repos")
library(httr)
source('~/Documents/Classes/Data Science/courses/03_GettingData/02_quiz/github.R')
git <- parseRepos("https://api.github.com/users/jtleek/repos")
source('~/Documents/Classes/Data Science/courses/03_GettingData/02_quiz/github.R')
git <- parseRepos("https://api.github.com/users/jtleek/repos")
View(git)
git
git[git$url == "https://github.com/jtleek/datasharing",]
git[,git$url]
git$url
git[git$url == "https://api.github.com/repos/jtleek/datasharing",]
install.packages("sqldf")
getwd()
setwd("/Users/lparayno/git/R/Getting_and_Cleaning_Data/02_quiz")
?csv
??csv
survey <- read.csv("./americancommunitysurvey.csv")
survey
sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
library(sqldf)
sqldf("select pwgtp1 from acs where AGEP < 50")
acs <- read.csv("./americancommunitysurvey.csv")
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select distinct AGEP from acs")
sqldf("select distinct AGEP from acs order by AGEP")
library(XML)
contact <- "http://biostat.jhsph.edu/~jleek/contact.html "
doc <- xmlTreeParse(contact, useInternal = TRUE)
contact <- "http://biostat.jhsph.edu/~jleek/contact.html"
doc <- xmlTreeParse(contact, useInternal = TRUE)
doc <- htmlTreeParse(contact, useInternal = TRUE)
doc
?nchar
doc
doc[10,]
download.file(contact, destfile = "./contact.html", method= "curl")
con <- readLines("./contact.html")
ten <- con[10]
length(ten)
nchar(ten)
specficLines <- c(con[10], con[20], con[30], con[100])
lapply(specificLines, nchar)
nchar(con[20])
nchar(con[30])
nchar(con[100])
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", destfile = "./ncep.for", method = "curl")
ncep <- read.fwf("./ncep.for", )
ncep <- read.fwf(file = "./ncep.for", skip = 4)
ncep <- read.fwf(file = "./ncep.for", skip = 4, widths = c(12, 7, 4, 9, 4, 9, 4, 9, 4))
ncep
head(ncep)
sum(ncep[,4])
sum(ncep[,9])
sum(ncep[,4]) + sum(ncep[,9])
